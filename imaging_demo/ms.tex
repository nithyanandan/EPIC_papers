% mnras_template.tex
%
% LaTeX template for creating an MNRAS paper
%
% v3.0 released 14 May 2015
% (version numbers match those of mnras.cls)
%
% Copyright (C) Royal Astronomical Society 2015
% Authors:
% Keith T. Smith (Royal Astronomical Society)

% Change log
%
% v3.0 May 2015
%    Renamed to match the new package name
%    Version number matches mnras.cls
%    A few minor tweaks to wording
% v1.0 September 2013
%    Beta testing only - never publicly released
%    First version: a simple (ish) template for creating an MNRAS paper

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Basic setup. Most papers should leave these options alone.
% \documentclass[a4paper,fleqn,usenatbib]{../mnras}
\documentclass[a4paper,fleqn,usenatbib]{mnras}

% MNRAS is set in Times font. If you don't have this installed (most LaTeX
% installations will be fine) or prefer the old Computer Modern fonts, comment
% out the following line
% \usepackage{newtxtext,newtxmath}
% Depending on your LaTeX fonts installation, you might get better results with one of these:
% \usepackage{mathptmx}
% \usepackage{txfonts}

% Use vector fonts, so it zooms properly in on-screen viewing software
% Don't change these lines unless you know what you are doing
\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}
% \pdfminorversion=5

%%%%% AUTHORS - PLACE YOUR OWN PACKAGES HERE %%%%%

% Only include extra packages if you really need them. Common packages are:
\usepackage{graphicx}	% Including figure files
\usepackage{amsmath}	% Advanced maths commands
\usepackage{amssymb}	% Extra maths symbols
\usepackage[flushleft]{threeparttable} % For table notes
\usepackage[caption=false]{subfig} % For subfloats

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%% AUTHORS - PLACE YOUR OWN COMMANDS HERE %%%%%

% Please keep new commands to a minimum, and use \newcommand not \def to avoid
% overwriting existing commands. Example:
%\newcommand{\pcm}{\,cm$^{-2}$}	% per cm-squared
\newcommand{\Nant}{N_\textrm{a}}
\newcommand{\Ngrid}{N_\textrm{g}} 
\newcommand{\Npix}{N_{\text{pix}}}
\newcommand{\dif}{\mathrm{d}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%% TITLE PAGE %%%%%%%%%%%%%%%%%%%

% Title of the paper, and the short title which is used in the headers.
% Keep the title short and informative.
\title[E-field Parallel Imaging Correlator]{A Generic and Efficient E-field Parallel Imaging Correlator for Next-Generation Radio Telescopes}

% The list of authors, and the short list which is used in the headers.
% If you need two or more lines of authors, add an extra line using \newauthor
\author[Thyagarajan et al.]{
Nithyanandan Thyagarajan,$^{1}$\thanks{E-mail: t\_nithyanandan@asu.edu}
Adam P. Beardsley,$^{1}$
Judd D. Bowman$^{1}$
\newauthor
and Miguel F. Morales$^{2}$
\\
% List of institutions
$^{1}$Arizona State University, School of Earth and Space Exploration, Tempe, AZ 85287, USA\\
$^{2}$University of Washington, Department of Physics, Seattle, WA 98195, USA\\
}

% These dates will be filled out by the publisher
\date{Accepted XXX. Received YYY; in original form ZZZ}

% Enter the current year, for the copyright statements etc.
\pubyear{2015}

% Don't change these lines
\begin{document}
\label{firstpage}
\pagerange{\pageref{firstpage}--\pageref{lastpage}}
\maketitle

% Abstract of the paper
\begin{abstract}
Modern radio telescopes are favouring densely packed array layouts with 
large numbers of antennas ($\Nant\gtrsim 1000$). Since the complexity of 
traditional correlators scales as $\mathcal{O}(\Nant^2)$, there will be a steep 
cost for realizing the full imaging potential of these powerful instruments. 
Through our generic and efficient E-field Parallel Imaging Correlator (EPIC), 
we present the first software demonstration of a generalized direct imaging 
algorithm, namely, the Modular Optimal Frequency Fourier (MOFF) imager. It takes 
advantage of the multiplication-convolution theorem of Fourier transforms. Not 
only does it bring down the cost for dense layouts to 
$\mathcal{O}(\Nant\log_2\Nant)$ but can also image from irregularly arranged 
heterogeneous antenna. EPIC is highly modular and parallelizable, implemented in 
object oriented Python, and publicly available. We have verified the images 
produced to be equivalent to those produced using traditional techniques to 
within a precision determined by coarseness of gridding. We have also validated 
our implementation on data observed with the Long Wavelength Array (LWA). Antenna 
layouts with a dense filling factor consisting of a large number of antennas such 
as LWA, the Square Kilometre Array, Hydrogen Epoch of Reionization Array, and 
Canadian Hydrogen Intensity Mapping Experiment will gain significant 
computational advantage by deploying EPIC. Inherent availability of calibrated 
time-domain images on digitizer writeout time-scales and vastly lower I/O 
bandwidth relative to visibility-based systems will make it a prime candidate 
for transient searches of Fast Radio Bursts (FRB) as well as planetary and 
exoplanetary phenomena. 
\end{abstract}

% Select between one and six entries from the list of approved keywords.
% Don't make up new ones.
\begin{keywords}
instrumentation: interferometers -- techniques: image processing -- techniques: interferometric
\end{keywords}

%%%%%%%%%%%%%%%%% BODY OF PAPER %%%%%%%%%%%%%%%%%%

\section{Introduction}

Radio astronomy is entering an era in which interferometers of hundreds to
thousands of individual antennas are needed to achieve desired survey speeds.
Nowhere is this more apparent than at radio frequencies below 1.4 GHz. The study
of the history of hydrogen gas throughout the universe's evolution is pushing
technology development towards arrays of low-cost antennas with large fields of
view and densely packed layouts. Similarly, the search for transient objects
and regular monitoring of the time-dependent sky is driving instruments in the
same direction with the added requirement of fast read-outs. A number of new 
telescopes are being or were developed around the world based on this new 
paradigm, including the Hydrogen Epoch of Reionization 
Array\footnote{http://reionization.org} (HERA), the Murchison Widefield Array 
(MWA;\citealt{tin13,bow13}), the Precision Array for Probing the Epoch of 
Reionization (PAPER; \citealt{par10}), the LOw Frequency ARray 
(LOFAR;\citealt{van13}), the Canadian Hydrogen Intensity Mapping Experiment 
(CHIME,\citealt{ban14}), the Long Wavelength Array (LWA, \citealt{ell13}), and 
the low frequency Square Kilometer Array (SKA1-Low \citealt{mel13}).

This paradigm shift requires a fundamentally new approach to the design of
digital correlators \citep{lon00}. Modern correlators calculate the cross-power
correlation between all antenna pairs in many narrow frequencies, forming
\emph{visibilities}, the fundamental measurement of traditional radio
interferometers. The computational requirements for a modern FX correlator scale
with the number of antenna pairs, or the square of the number of antennas $\sim
\Nant^2$ \citep{bun04}. For this reason traditional correlators have difficulty
scaling to thousands of antennas. As an example, the full HERA correlator for
352 dishes with 200 MHz of bandwidth requires 212 trillion complex multiplies
and adds per second (TMACS). Future arrays with thousands of collecting elements
will require orders of magnitude more computation, making the correlator the
dominant cost.

For certain classes of radio arrays there is an alternative to the FX correlator
that can lower the computational burden by directly performing a spatial Fast
Fourier Transform \citep[FFT;][]{coo65} on the electric fields measured by each 
antenna in the array at each time step, removing the cross-correlation step. 
This relieves the computational scaling from the harsh $\Nant^2$ to the more 
gentle envelope of $\sim\Ngrid\log_2\Ngrid$, where $\Ngrid$ is the number of 
grid points in the Fourier transform \citep[e.g.][]{mor11,teg09,teg10}. This 
architecture is often referred to as a ``direct imaging'' correlator because it 
eliminates the intermediate cross-correlation data products of the FX and XF 
correlators, but instead directly forms images from the electric field 
measurements.

Direct imaging correlators have begun to be explored on deployed arrays including
the Basic Element for SKA Training II (BEST-2) array \citep{fos14}, the Omniscope
\citep{zhe14}, and an earlier incarnation at higher frequencies with the intent
of pulsar timing \citep{oto94, dai00}. However, each of these examples make
assumptions about the redundancy of the array layout, and require the collecting
elements are identical. On the other hand, the MOFF algorithm achieves the same
$\Ngrid \log_2 \Ngrid$ computational scaling without placing any restriction on
antenna placement, can accommodate non-identical beam patterns, and is provably 
optimal \citep{mor11}. This algorithm uses the antenna beam patterns to 
grid the electric field measurements to a regular grid in the software 
holography/A-transpose fashion \citep{mor09,bha08,teg97b} before performing the
spatial FFT. This process has been shown to theoretically produce a data product
identical to images produced from traditional visibility-based techniques.

Here we present the first software implementation of the MOFF correlator, and
announce the public release of the E-field Parallel Imaging Correlator (EPIC)
code. EPIC is a highly parallel, object oriented Python package that primarily 
implements the MOFF imaging algorithm besides emulating real-life telescopes and 
FX/XF correlators in software, and includes a visibility-based imaging technique 
for reference. It is intended to provide a development platform to test different 
imaging approaches, characterize scaling relations and serve as a stepping stone 
for real-life GPU/FPGA-based implementation on telescopes.

We begin with a technical description of the algorithm in \S\ref{sec:math}, 
then discuss our particular implementation in \S\ref{sec:software}. We then 
verify the output data quality from our code in \S\ref{sec:verify} by presenting 
simulated images from both the EPIC correlator and comparing to a simulated FX 
correlator. We also demonstrate the performance with real-world data from the 
LWA. In \S \ref{sec:analysis}, we explore the scalability of the algorithm in the 
context of several array design choices. We identify specific array design 
classes where the EPIC correlator -- is computationally more efficient; and in 
the field of transients, demands significantly lesser I/O bandwidth relative to 
visibility-based approaches. We conclude and discuss future research prospects 
in \S\ref{sec:conclusions}.

\section{Mathematical Framework}\label{sec:math}

We provide a brief summary of the mathematical equivalence of the MOFF and 
FX correlators detailed in \citet{mor11}. We first relate the dirty image produced 
from visibilities to the electric fields of astrophysical sources, then show that 
operations can be reordered to produce the same images at a lower 
computational cost.

Electric fields from astrophysical sources, $E(\hat{\mathbf{s}})$, in the sky
coordinate system denoted by sine-projected unit vector $\hat{\mathbf{s}}$, 
propagate towards the observer as:
\begin{align}
  \widetilde{E}(\mathbf{r}) &= \int E(\hat{\mathbf{s}})\,e^{-i2\pi\mathbf{r}\cdot\hat{\mathbf{s}}}\,\dif^2\hat{\mathbf{s}},
\end{align}
where, $\mathbf{r}$ denotes the observer's location (measured in wavelengths 
relative to some arbitrary origin) and $\widetilde{E}
(\mathbf{r})$ is the propagated electric field. Thus the propagated electric
field is a linear superposition of the electric fields emanating from
astronomical sources with appropriate complex phases. It can also be described
as a Fourier transform of the electric fields in the sky coordinates. 

An antenna, $a$, measures a phased sum of these propagated electric fields over
its effective collecting area with an additive receiver noise:
\begin{align}\label{eqn:measured-E-field}
  \widetilde{E}_a &= \int \widetilde{W}_a(\mathbf{r}-\mathbf{r}_a)\,\widetilde{E}(\mathbf{r})\,\dif^2\mathbf{r} + \widetilde{n}_a \\
                  &= \int \widetilde{W}_a(\mathbf{r}-\mathbf{r}_a) \left[ \int E(\hat{\mathbf{s}})\,e^{-i2\pi\mathbf{r}\cdot\hat{\mathbf{s}}}\,\dif^2\hat{\mathbf{s}} \right] \dif^2\mathbf{r} + \widetilde{n}_a \\
                  &= \int {W}_a(\hat{\mathbf{s}})\,E(\hat{\mathbf{s}})\,e^{-i2\pi\mathbf{r}_a\!\cdot\,\hat{\mathbf{s}}}\,\dif^2\hat{\mathbf{s}} + \widetilde{n}_a
\end{align}
where, $\widetilde{W}_a(\mathbf{r})$ is the aperture electric field illumination
pattern of the antenna and its Fourier transform, $W_a(\hat{\mathbf{s}})$, is the
directional antenna voltage response.

Interferometers measure {\it visibilities} -- the degree of coherence between
electric fields measured by a pair of antennas \citep{van34,zer38,tho01}.
A visibility, $\widetilde{V}_p$, can be written as:
\begin{align}
  \widetilde{V}_p &= \left\langle \widetilde{E}_a\widetilde{E}_b^\star \right\rangle_t \label{eqn:cc-vis}\hfill\\
  		&= \left\langle \left[ \int {W}_a(\hat{\mathbf{s}})\,E(\hat{\mathbf{s}})\,e^{-i2\pi\mathbf{r}_a\!\cdot\,\hat{\mathbf{s}}}\,\dif^2\hat{\mathbf{s}} + \widetilde{n}_a \right] \right. \nonumber\\
		&\qquad \times \left.\left[ \int {W}^\star_b(\hat{\mathbf{s'}})\,E^\star (\hat{\mathbf{s'}})\,e^{i2\pi\mathbf{r}_b\!\cdot\,\hat{\mathbf{s'}}}\,\dif^2\hat{\mathbf{s'}} + \widetilde{n}^\star_b \right] \right\rangle_t \\
                  &= \iint {W}_a(\hat{\mathbf{s}}) {W}^\star_b(\hat{\mathbf{s'}}) \left\langle E(\hat{\mathbf{s}}) E^\star(\hat{\mathbf{s'}}) \right\rangle_t e^{-i2\pi(\mathbf{r}_a\!\cdot\,\hat{\mathbf{s}}-\mathbf{r}_b\!\cdot\,\hat{\mathbf{s'}})}\,\dif^2\hat{\mathbf{s}}\,\dif^2\hat{\mathbf{s'}},
\end{align}
where we have brought the time average into the integral under the assumption that 
the aperture illumination pattern does not change over the time-scale of the 
averaging and $\star$ denotes complex conjugation. This expression can be further 
simplified with the sky brightness, 
$I(\hat{\mathbf{s}})= \left\langle E(\hat{\mathbf{s}}) E^\star(\hat{\mathbf{s'}}) 
\right\rangle_t  \delta(\hat{\mathbf{s}}-\hat{\mathbf{s'}})$, and defining the 
antenna pair sky power response function (or the directional antenna power pattern), 
$B_p(\hat{\mathbf{s}})~\equiv~{W}_a(\hat{\mathbf{s}})~{W}^\star_b(\hat{\mathbf{s}})$. 
The result is the visibility expressed in terms of the sky brightness, the power 
response, and uncorrelated noise terms which we group into $\widetilde{n}_p$.
\begin{equation}
\widetilde{V}_p = \int e^{-i2\pi\mathbf{u}_p\!\cdot\,\hat{\mathbf{s}}}\,B_p(\hat{\mathbf{s}})\,I(\hat{\mathbf{s}})\,\dif^2\hat{\mathbf{s}} + \widetilde{n}_p,
\end{equation}
where, the baseline coordinate $\mathbf{u}_p=\mathbf{r}_a-\mathbf{r}_b$ is the 
vector separation between the two antennas. This signifies that the visibility 
($\widetilde{V}_p$) measured between a
pair of antennas ($p$) is obtained by the multiplying the sky brightness
$I(\hat{\mathbf{s}})$ by the antenna power response $B_p(\hat{\mathbf{s}})$ and
Fourier transforming from the directional coordinates ($\hat{\mathbf{s}}$) to $uv$
coordinates, which are then sampled at the locations of the antenna spacings (or
baselines), namely, $\mathbf{u}_p$, and added to the receiver noise $n_p$. 

This can be equivalently re-written as:
\begin{align}\label{eqn:software-holography}
  \widetilde{V}_p &= \int \widetilde{B}(\mathbf{u}^\prime-\mathbf{u}) \left[\int e^{-i2\pi\mathbf{u}.\hat{\mathbf{s}}}\,I(\hat{\mathbf{s}})\,\dif^2\hat{\mathbf{s}}\right]\dif^2\mathbf{u} + n_p,
\end{align}
where, $\widetilde{B}(\mathbf{u})$ denotes the $uv$-space antenna power response
obtained by a Fourier transform of $B(\hat{\mathbf{s}})$. Effectively, the
multiplication in image space by $B(\hat{\mathbf{s}})$ has been replaced by a
convolution with $\widetilde{B}(\mathbf{u})$ in $uv$-space. This is the software
holographic equivalent of a traditional FX correlator output. 

Hereafter, we adopt the matrix notation of \citet{mor11}, where vectors are 
represented with single coordinates, and matrices are represented by two 
coordinates denoting the spaces the operator transforms between. 
In this notation, the above measurement equation can be expressed as:
\begin{align}
  \mathbf{m}(\mathbf{v}) &= \widetilde{\mathbf{B}}(\mathbf{v},\mathbf{u})\,\mathbf{F}(\mathbf{u},\hat{\mathbf{s}})\,\mathbf{I}(\hat{\mathbf{s}}) + \mathbf{n}(\mathbf{v}),
\end{align}
where the sky brightness $\mathbf{I}(\hat{\mathbf{s}})$ is Fourier transformed using
$\mathbf{F}(\mathbf{u},\hat{\mathbf{s}})$ and the resultant spatial coherence
function is weighted and summed using the antenna power response,
$\widetilde{\mathbf{B}}(\mathbf{v},\mathbf{u})$ in $uv$-space sampled at the baseline
location to obtain the measured visibilities:
\begin{align}
  \mathbf{m}(\mathbf{v}) &= \left\langle \widetilde{\mathbf{E}}(\mathbf{a})\,\widetilde{\mathbf{E}}^\star(\mathbf{a}^\prime)\right\rangle_t, \label{eqn:matrix-cc-vis}
\end{align}
where $\mathbf{m}(\mathbf{v})$ denotes visibilities measured by cross-correlating
measured antenna electric fields over all possible pairs of $\mathbf{a}$ and
$\mathbf{a}^\prime$. It is the same as equation~\ref{eqn:cc-vis} written in
matrix notation.

Using the optimal map-making formalism \citep{teg97a,teg97b}, a software
holography image is formed using \citep{mor09}:
\begin{align}
  \mathbf{I}^\prime(\hat{\mathbf{s}}) &= \mathbf{F}^\textrm{T}(\hat{\mathbf{s}},\mathbf{u})\,\widetilde{\mathbf{B}}^{\,\textrm{T}}(\mathbf{u},\mathbf{v})\,\mathbf{N}^{-1}(\mathbf{v},\mathbf{v})\,\mathbf{m}(\mathbf{v}) \label{eqn:dirty-image-FX}
\end{align}
where the measured visibilities are weighted by the inverse of the system noise,
followed by a gridding process using the holographic antenna power response as 
the gridding kernel, followed by a Fourier transform to create an image
$\mathbf{I}^\prime(\hat{\mathbf{s}})$. This is the optimal estimate of the true 
image $\mathbf{I}(\hat{\mathbf{s}})$ given the visibility measurements.

The intermediate step of gridding with the antenna power response can be 
expressed as a convolution of a data vector generated by gridding the electric 
fields directly with the antenna illumination pattern.
\begin{align}
\widetilde{\mathbf{B}}^{\,\textrm{T}}(\mathbf{u},\mathbf{v})\,\mathbf{N}^{-1}(\mathbf{v} ,\mathbf{v})\,\mathbf{m}(\mathbf{v}) &= \left\langle \left[\widetilde{\mathbf{W}}^\textrm{T}_a(\mathbf{r},\mathbf{a})\, \widetilde{\mathbf{N}}^{-1}\!(\mathbf{a},\mathbf{a})\, \widetilde{\mathbf{E}}(\mathbf{a})\right]\right. \nonumber\\ 
&\quad\ast\left.\left[\widetilde{\mathbf{W}}_a(\mathbf{r},\mathbf{a})\, \mathbf{N}^{-1}\!(\mathbf{a},\mathbf{a})\, \widetilde{\mathbf{E}}^\star(\mathbf{a})\right]\right\rangle_t\label{eqn:e-field-conv}
\end{align}

We can then use the multiplication-convolution theorem to move the convolution in 
Equation \ref{eqn:e-field-conv} to a square after the Fourier transform in 
Equation 
\ref{eqn:dirty-image-FX}.
\begin{align}
  \mathbf{I}^\prime(\hat{\mathbf{s}}) &= \left\langle \left|\,\mathbf{F}^\textrm{T}(\hat{\mathbf{s}},\mathbf{r})\,\widetilde{\mathbf{W}}^\textrm{T}(\mathbf{r},\mathbf{a})\,\widetilde{\mathbf{N}}^{-1}(\mathbf{a},\mathbf{a})\,\widetilde{\mathbf{E}}(\mathbf{a})\,\right|^2\right\rangle_t. \label{eqn:dirty-image-MOFF}
\end{align}
The term inside the angular brackets before squaring has a very similar form as
that in equation~\ref{eqn:dirty-image-FX}. It signifies that the measured antenna
electric fields are weighted by the antenna noise, weighted and gridded by the
antenna aperture kernel, Fourier transformed and finally squared to obtain the
same image estimate that would have been obtained using equation~
\ref{eqn:dirty-image-FX}. 

Equation \ref{eqn:dirty-image-MOFF} is the optimal imaging equation used by the 
MOFF algorithm. While mathematically equivalent to Equation~
\ref{eqn:dirty-image-FX}, squaring in image space rather than convolving in $uv$ 
space potentially saves orders of magnitude in computation.

There are some important differences between the two techniques:
\begin{enumerate}
\item The time-averaging cannot be performed on a stochastic measurement but
  only on its statistical properties. In visibility-based imaging, the 
  visibilities measured between antenna pairs represent spatial correlations 
  which can be time-averaged followed by gridding and imaging. However, in MOFF 
  imaging both antenna and gridded electric fields are stochastic and therefore 
  must be imaged and squared before time-averaging. 
\item In visibility-based imaging, electric fields measured by antennas are not 
  correlated with themselves and hence lack zero spacing measurements. In 
  contrast, in MOFF imaging, since the gridded electric fields are imaged and 
  squared, they retain information from auto-correlated electric fields at zero 
  spacing and thus yield the true total power of the imaged field.
\end{enumerate} 

\section{Software Implementation}\label{sec:software}

We have implemented the MOFF imaging technique in our ``E-field Parallel Imaging
Correlator'' -- a highly parallelized Object Oriented Python 
package,\footnote{The E-field Parallel Imaging Correlator (EPIC) package can be 
accessed at https://github.com/nithyanandan/EPIC} now publicly available. Besides 
implementing the MOFF imaging algorithm it also includes visibility-based imaging 
using the software holography technique and a simulator for generating electric 
fields from a sky model. 

% \subsection{Data Flow}

EPIC can accept dual-polarization inputs and produce images of all four 
instrumental cross-polarizations. Currently two data input formats exist for 
reading in the 
electric field time samples measured by the antennas -- simulated electric 
fields based on a sky model using the simulator packaged with EPIC; and LWA 
data. Efforts to build interfaces for data from other telescopes are underway.

Fig.~\ref{fig:MOFF-flowchart} shows the flowchart for MOFF imaging. The
propagated electric fields are shown on the left at different time stamps,
$t_1\ldots t_\textrm{M}$. At each time stamp, the electric fields measured by
antennas are denoted by $E_1(t)\ldots E_\textrm{N}(t)$. The F-engine performs a
temporal Fourier transform on the electric field time-series to obtain electric
field spectra $\widetilde{E}_1(f)\ldots \widetilde{E}_\textrm{N}(f)$ 
($\widetilde{\mathbf{E}}(\mathbf{a})$ in matrix notation) for each of the 
antennas. Each of the complex antenna gains are calibrated to correct the 
corresponding electric field spectra. These calibrated electric fields are 
gridded using an antenna-based gridding convolution function after which it is 
spatially Fourier transformed and squared to obtain an image cube for every time 
stamp. These images are then time-averaged to obtain the accumulated image 
$I(f)$ ($\mathbf{I}(\hat{\mathbf{s}})$ in matrix notation).

\begin{figure}
  \includegraphics[width=\columnwidth]{figure1}
  % \includegraphics[width=\columnwidth]{MOFF_flowchart}
  % \includegraphics[width=\columnwidth]{MOFF_flowchart.eps}
  \caption{A flowchart of MOFF imaging in EPIC. The propagated electric fields
    shown on the left are measured as time-series $E_1(t)\ldots E_\textrm{N}(t)$
    by the antennas $\textrm{A}_1\ldots \textrm{A}_\textrm{N}$ which are then 
    Fourier transformed by the F-engine to produce electric field spectra 
    $\widetilde{E}_1(f)\ldots \widetilde{E}_\textrm{N}(f)$. They are calibrated 
    and gridded. The gridded electric fields $\widetilde{E}_\textrm{g}(f)$ from 
    each time series are imaged to produce images 
    $I_1(f)\ldots I_\textrm{M}(f)$. These images are time-averaged to obtain the 
    final image $I(f)$.}
  \label{fig:MOFF-flowchart}
\end{figure}

Fig.~\ref{fig:FX-flowchart} shows the flowchart for a visibility-based software 
holographic imaging from a FX correlator. The antenna-based F-engine is identical 
to that in the MOFF processing. The electric field spectra from each antenna are 
then cross-multiplied in the X-engine with those from all other antennas to 
obtain the visibilities $\widetilde{V}_\textrm{p}(f)$ ($\mathbf{m}(\mathbf{v})$ 
in matrix notation). They are calibrated and time-averaged to obtain 
$\langle \widetilde{V}_\textrm{p}(f)\rangle$ which are then gridded and imaged to 
obtain the image $I(f)$. The $I(f)$ obtained from both techniques are 
theoretically identical as explained in \S\ref{sec:math}.

\begin{figure}
  \includegraphics[width=\columnwidth]{figure2}
  % \includegraphics[width=\columnwidth]{FX_flowchart}
  % \includegraphics[width=\columnwidth]{FX_flowchart.eps}
  \caption{A flowchart of visibility-based software holographic imaging in EPIC. 
    The FX process flow shares the F-engine with the MOFF process. Following the 
    F-engine, the electric fields pass through the X-engine to produce 
    visibilities $\widetilde{V}_\textrm{p}(f)$ which are calibrated and 
    time-averaged. Then they are gridded to obtain the gridded visibilities 
    $\widetilde{V}_\textrm{g}(f)$ which are then Fourier transformed to obtain 
    the image, $I(f)$.}
  \label{fig:FX-flowchart}
\end{figure}

Here we discuss the components of these architectures in detail. 

\par\medskip
\noindent {\bf Antenna-to-Grid Mapping}
\par\medskip
\noindent A grid is generated on the coordinate system in which antenna 
locations are specified with a grid spacing. The grid spacing can be controlled 
by the user. By default, it is set to be $\le\lambda/2$ even at the 
lowest wavelength to ensure there is no aliasing even from regions of the sky 
far away from the field of view. The number of locations on the grid is 
restricted to be a power of 2 for efficient use of FFT. 

The gridding kernel in the simplest case is given by the antenna aperture
illumination function, $\widetilde{B}(\mathbf{r}-\mathbf{r}_a)$, which can
be specified either by a functional form or as a table of values against 
locations around the antennas. A nearest neighbor mapping from all antenna 
footprints to grid locations is created using an efficient k-d tree algorithm 
\citep{man99}. There is no restriction here that the aperture illumination 
function has to be identical across antennas. 

In the most general case, this gridding kernel could contain information on
$w$-projection effects, and other time-dependent ionospheric effects. For a
stationary antenna array in the absence of any time-dependent effects, this
mapping must only be determined once in the antenna array coordinate frame. The
antenna-to-grid mapping matrix, $\mathbf{M}(\mathbf{r},\mathbf{a})$ is described
as a transformation matrix from the space of measured electric fields by the 
antennas ($\mathbf{a}$) to the antenna array grid denoted by the coordinate 
$\mathbf{r}$. Since each antenna occupies a footprint typically the size of its 
aperture, $\mathbf{M}(\mathbf{r},\mathbf{a})$, which is generally of size
$\Ngrid\times \Nant$, reduces to a sparse block-diagonal matrix
with only $\Nant$ blocks and roughly $N_\textrm{k}$ non-zero entries per
block, where $N_\textrm{k}$ is the number of grid points that fall inside an
antenna's footprint. This sparse matrix is stored in a Compressed Sparse Row 
(CSR) format. Fig.~\ref{fig:a2g-mapping} illustrates the antenna-to-grid mapping
matrix and the grid containing the mapped aperture footprints of the antennas.

\begin{figure}
  \includegraphics[width=\columnwidth]{figure3}
  % \includegraphics[width=\columnwidth]{a2g_mapping}
  % \includegraphics[width=\columnwidth]{a2g_mapping.eps}
  \caption{Block diagram of an antenna-to-grid mapping. A sparse block-diagonal
    matrix of total size $\Ngrid\times \Nant$ is created where each
    block contains roughly the number of pixels covered by the respective kernel.
    The antenna aperture illumination kernels do not have to be identical to each
    other. A discrete set of arbitrarily placed antennas are now placed on to a
    regular grid.}
  \label{fig:a2g-mapping}
\end{figure}

\par\medskip
\noindent {\bf Temporal Fourier transform}
\par\medskip
\noindent This module is common to the MOFF and visibility-based imaging 
techniques. Time samples of electric fields measured by the antenna and 
digitized by the A/D converter is Fourier transformed to generate electric 
field spectra. This step can be parallelized across antennas%  as shown in 
% Fig.~\ref{fig:f-engine}
. The output is then fed to either MOFF or 
visibility-based imaging pipelines.

% \begin{figure}
%   \includegraphics[width=\columnwidth]{figure4}
%   % \includegraphics[width=\columnwidth]{parallel_F_engine}
%   % \includegraphics[width=\columnwidth]{parallel_F_engine.eps}
%   \caption{Block diagram of a F-engine. The electric field data streams from
%     antennas are Fourier transformed in parallel to generate electric field
%     spectra.}
%   \label{fig:f-engine}
% \end{figure}

\par\medskip
\noindent {\bf Calibration}
\par\medskip
\noindent Calibration of direct imaging correlators remains a challenge. Contrary
to the FX data flow, direct imagers mix the signals from all antennas before
averaging and writing to disk. It is therefore essential to apply gain solutions 
before the gridding step. Previous efforts have resorted to applying FX-generated
calibration solutions \citep{zhe14,fos14}, or integrating a dedicated FX 
correlator which periodically forms the full visibility matrix 
\citep{wij09,dev09}. 

In a companion paper \citep{bea16}, we demonstrate a novel calibration 
technique (EPICal) which leverages the data products formed by direct imaging 
correlators to estimate antenna complex gains. This method correlates the antenna 
electric field signals with an image pixel from the output of the correlator in 
the feedback calibration fashion outlined in \citealt{mor11} (illustrated in 
Fig.~\ref{fig:MOFF-flowchart} by the arrow leading from the imager to the 
calibration block). Furthermore it allows for arbitrarily complex sky models, 
and following the MOFF algorithm places no restriction on array layout, and 
accounts for non-identical antenna beam patterns. Direction dependent calibration 
can be achieved by correlating antenna signals with output pixels in the 
direction of $N_\textrm{c}$ calibration sources, then fitting for a functional 
model of the sky. Since antennas are only correlated with calibrator pixels, the 
computational complexity scales as $\sim N_\textrm{a} N_\textrm{c}$. 

The calibration module included in EPIC allows for application of pre-determined 
calibration solutions, or can solve for the complex gains using the EPICal 
algorithm.

\par\medskip
\noindent {\bf Gridding Convolution}
\par\medskip
\noindent The antenna array aperture illumination over the entire grid,
$\widetilde{\mathbf{W}}(\mathbf{r})$, is obtained by a projection of the 
individual antenna aperture illuminations:
\begin{align}\label{eqn:gridding-convolution}
  \widetilde{\mathbf{W}}(\mathbf{r}) &= \sum_a \widetilde{\mathbf{W}}_a(\mathbf{r}-\mathbf{r}_a) \\
                            &= \mathbf{M}(\mathbf{r},\mathbf{a})\,\mathcal{I}(\mathbf{a}),
\end{align}
where, $\mathcal{I}(\mathbf{a})$ is a row of ones. This is achieved by
efficient multiplication with the sparse matrix created in the antenna-to-grid
mapping process using the sparse matrices module in Python SciPy package. 
Unless $\widetilde{\mathbf{W}}(\mathbf{r})$ includes time-dependent
effects of the ionosphere or the instrument, it needs to be computed just once
for the entire observation. However, the gridding of electric fields must be
computed at every readout of the electric field spectra,
\begin{align}
  \widetilde{\mathbf{E}}(\mathbf{r}) &= \mathbf{M}(\mathbf{r},\mathbf{a})\,\widetilde{\mathbf{E}}(\mathbf{a}).
\end{align}

\par\medskip
\noindent {\bf Spatial Fourier Transform}
\par\medskip
\noindent Before the spatial Fourier transform, the gridded electric fields are 
padded with zeros in order to match the grid size and angular size of each image 
pixel that would have been obtained with the software holography output from an 
FX correlator. 

In MOFF imaging, these are spatially Fourier transformed followed by a squaring
operation at every time stamp for every frequency channel. In visibility-based 
imaging, the spatial Fourier transform is performed only once per integration 
time-scale and does not include a squaring operation.

\par\medskip
\noindent {\bf Time-averaging}
\par\medskip
\noindent In MOFF imaging, the measured antenna electric fields and the 
corresponding holographic electric field images are zero-mean stochastic 
quantities. Hence, they cannot be time-averaged to reduce noise. The statistical 
quantity stable with time in this case are the square of the holographic 
electric field images. Thus, squared images have to be formed at every instant 
of time before averaging as indicated in equation~\ref{eqn:dirty-image-MOFF}.

In contrast, visibilities measured by an antenna are statistically stable within
an integration time interval. Hence, they are averaged after calibration as shown
in equation~\ref{eqn:cc-vis}. It is advantageous to average them in visibilities
before imaging because the repeated cost of spatial FFT can be avoided. Since 
this averaging has been performed already on the visibilities over an integration 
time-scale, the imaging step has to be performed only once per integration cycle. 

A high level software architecture of the EPIC package is described in the 
appendix \S\ref{sec:software-modules} for the interested reader.

\section{Verification}\label{sec:verify}

In order to verify the accuracy of the EPIC code, we characterize the images 
produced through simulations. We simulate electric field streams from a model 
sky and process the data through both the MOFF and a visibility-based imaging 
algorithm. We then compare the output images to demonstrate their equivalence.

\subsection{Simulations}\label{sec:sim}

We use the EPIC simulator to generate stochastic electric field samples from a 
sky model consisting of 10 point sources of flux densities 10~Jy each at random 
locations. In our simulations, we use 64 frequency channels each of width 
$\Delta f = 40$~kHz. The number of time stamps integrated in one integration 
cycle was kept at eight where each A/D timeseries is $1/\Delta f=25\,\mu$s long. 
We use the MWA array layout \citep{bea12} for demonstration. Only the inner 51 
tiles within a square bounding box of 150~m on each side were used. We assumed 
all tiles are identical and have a square shaped electric field illumination 
footprint 4.4~m on each side. Besides the stochastic sky noise present in the 
simulated electric fields, no noise from the instrument is added.

\subsection{Antenna auto-correlations}\label{sec:rm-autocorr}

Before the outputs can be compared, we describe the elimination of a minor 
mathematical difference between the two techniques. The squaring operation under 
MOFF imaging in the image plane introduces antenna auto-correlations around the 
zero spacing in the $uv$-plane which are absent in traditional visibility-based 
imaging. In order to facilitate a robust comparison between MOFF and 
visibility-based imaging techniques, these auto-correlations are removed from 
the MOFF algorithm output, which is otherwise not an essential part of the core 
algorithm. We describe below how they are removed. 

The shape and extent of these auto-correlations can be estimated from the 
antenna aperture illumination pattern. The aperture illumination patterns
are already available from the gridding step. Fig.~\ref{fig:autocorr_wts_PB} 
shows the estimated weights from antenna auto-correlations in the $uv$-plane 
(left) and the corresponding response in the image plane (right). The latter 
is simply the directional antenna power response. 

\begin{figure}
  \includegraphics[width=\columnwidth]{figure4}
  % \includegraphics[width=\columnwidth]{autocorr_uvwts_pbeam}
  % \includegraphics[width=\columnwidth]{autocorr_uvwts_pbeam.png}
  \caption{The auto-correlation of weights of a square shaped antenna aperture
    in the $uv$ plane (left) and the corresponding directional antenna power 
    response on the sky (right) in coordinates specified by direction cosines. 
    The antenna auto-correlation weights are normalized to a sum
    of unity yielding a peak response of unity in the antenna's directional
    power pattern on the sky. The color scale for the directional power 
    pattern is logarithmic. The black circle indicates the sky horizon and
    values beyond it are not physical and hence ignored.}
  \label{fig:autocorr_wts_PB}
\end{figure}

We inverse Fourier transform the squared images and beams back to the $uv$ 
plane and subtract the estimated auto-correlation kernel scaled to the peak 
value centreed at the zero spacing pixel. The final averaged image is obtained 
by Fourier transforming the $uv$ plane data and weights with the 
auto-correlations subtracted to the image plane. These images are now comparable 
to those obtained from visibility-based imaging. This step of removing 
auto-correlations is optional and required to be performed only once per 
integration time-scale and does not add significant cost to the full operation.

\subsection{Comparison of outputs}\label{sec:diff}

We investigate the two imaging algorithms for differences from the point of 
view of the quality of their outputs. We begin by comparing the images produced 
with the two approaches. 

Fig.~\ref{fig:MOFF-FX-image} shows the dirty images (top) and synthesized beams
(bottom) obtained with antenna-based MOFF and FX visibility-based imaging 
algorithms packaged in EPIC. The antenna auto-correlations that correspond to 
zero spacing have been removed from the correlated weights and data in the 
$uv$ plane, the MOFF image and the corresponding synthesized beam as 
described in \S\ref{sec:rm-autocorr}. The sky positions of the simulated sources 
are indicated by solid black circles. The reconstructed sky image has the 
simulated sources at the expected sky positions in either case. Both algorithms 
result in images and synthesized beams that are well matched with each other. 
Their fluxes are modulated by a multiplicative power pattern corresponding to 
that of a uniform square aperture. 

\begin{figure}
  \includegraphics[width=\columnwidth]{figure5}
  % \includegraphics[width=\columnwidth]{MOFF_FX_comparison_10_random_source_positions_4_iterations_test_aperture_zoomed}
  % \includegraphics[width=\columnwidth]{MOFF_FX_comparison_10_random_source_positions_4_iterations_test_aperture_zoomed.eps}
  \caption{Dirty images (top) and synthesized beams (bottom) obtained from 
    simulated data using EPIC implementation of antenna-based MOFF algorithm 
    (left) and visibility-based imaging (right). The solid black circles in the
    top panels indicate the simulated source positions. The antenna 
    auto-correlations at zero-spacing have been removed from the MOFF images. 
    The images in either case reconstruct the sources at the right locations 
    with the fluxes expected after multiplication by the antenna power pattern. 
    The synthesized beams from the two algorithms are well matched in size and
    shape. The overall modulation by the power pattern is seen clearly in both
    images.}
  \label{fig:MOFF-FX-image}
\end{figure}

\begin{figure}
  \includegraphics[width=\columnwidth]{figure6}
  \caption{.}
  \label{fig:f-engine}
\end{figure}

Now we investigate the gridded cross-correlation weights in the $uv$-plane. 
Fig.~\ref{fig:MOFF-FX-uvwts} shows the correlated weights obtained with MOFF 
imaging (left) and visibility-based imaging (right). There are two notable 
differences. The first is in the weights around zero spacing. Though both show a
dominant void around zero-spacing, the void obtained with MOFF algorithm shows 
many pixels with non-zero weights. In contrast, the zero-spacing void from 
traditional imaging consists of predominantly zero-valued pixels. The second 
difference is in the weights outside the zero-spacing void. In some regions they 
are different from each other at the few percent level though the sum of weights 
in these regions is the same. For instance, note the difference in weights at 
$(u,v)\approx (2,-10)$. The reason for these differences is described below.

The gridding step in MOFF imaging samples the antenna footprint (either in 
analytic or lookup table formats) at the grid locations. Coverage of grid pixels 
by an antenna footprint may be $\sim 1$ pixel narrower particularly at the 
edge of the footprint along one or both directions relative to that from another 
identical antenna but with a fractionally different location relative to the 
grid. This depends on the exact location of the centre of the antenna relative 
to the grid and the coarseness of grid spacing. This first order loss of 
precision of the sampled footprint propagates to second order ($\sim 2$ pixels) 
upon correlation of the discretized weights. In other words, the correlated 
weights may suffer further loss of precision in their sampled footprint after 
correlation of two footprints each of which could be less precise to first 
order. On the other hand, in visibility-based imaging, a directly sampled $uv$ 
plane antenna power response (which is theoretically identical to the correlation 
of individual antenna footprints) centreed on a baseline has a loss in precision 
at most to first order. Thus, although in the limit of infinitesimally small 
grid spacing they should be identical, the coarseness of grid spacing introduces 
subtle differences between the two.

These differences which are dependent on the coarseness of grid spacing can be 
mitigated by making the grid spacing finer at the expense of increased 
computational cost. Residuals centreed around zero spacing can also be lowered 
by subtracting each auto-correlation of antenna weights separately by using the 
shape and extent of the sampled footprint appropriate for that specific antenna 
aperture. This is a general solution applicable even in case of heterogeneous 
antenna arrays and is under active development for EPIC.

\begin{figure}
  \includegraphics[width=\columnwidth]{figure7}
  % \includegraphics[width=\columnwidth]{MOFF_FX_comparison_uvwts_test_aperture_zero_spacing_removed}
  % \includegraphics[width=\columnwidth]{MOFF_FX_comparison_uvwts_test_aperture_zero_spacing_removed.eps}
  \caption{.}
  \label{fig:MOFF-FX-uvwts}
\end{figure}

We study the effect of the differences in gridded weights on the image plane. 
Fig.~\ref{fig:psf-diff} shows the difference between the synthesized beams 
obtained with the two methods. A difference map between the two synthesized 
beams is shown on top. The amplitude of the difference appears to be 
modulated by the directional power response of the antenna. At the bottom, 
in radial bins, the rms of the synthesized beam (gray) and the rms of the 
difference map (black) are plotted in percentage units relative to the peak 
(to be read using the axis on the left side of the plot). The antenna power 
pattern (red; to be read using the scale on the right) is plotted for reference. 

\begin{figure}
  \includegraphics[width=\columnwidth]{figure8}
  % \includegraphics[width=\columnwidth]{diff_psf_MOFF-FX_test_aperture}
  % \includegraphics[width=\columnwidth]{diff_psf_MOFF-FX_test_aperture.eps}
  \caption{Map of difference between the synthesized beams obtained with the 
    two methods (left) and radial statistics of the synthesized beams and 
    their differences (right). The radial variations of rms of the synthesized 
    beam (gray) and that of the rms of the difference (black) are shown as 
    percentage of the peak synthesized beam. Radially averaged directional 
    antenna power response in absolute scale is shown in red and is to be read 
    with the scale on the right side of the axis. The maximum difference is of 
    the order of a few percent. Amplitude of the rms of the difference is 
    modulated by the power pattern of the antenna.}
  \label{fig:psf-diff}
\end{figure}

The synthesized beam rms is proportional to the antenna power pattern as 
expected from a point spread function uncorrected for the antenna power pattern. 
The rms of differenced synthesized beams is also modulated by the antenna power 
pattern. The rms of the difference is definitely lesser than the rms of the 
synthesized beam in the central regions up to $(l^2+m^2)^{1/2}\lesssim 0.3$. This 
implies that the beams are well matched in the central regions. In the outer 
regions, their mismatch is comparable to the rms of synthesized beams. This 
indicates the two synthesized beams are not completely randomly different from 
each other in which case the rms of the difference would have been 
$\approx \sqrt{2}$ higher than the rms of the each of the synthesized beams. 
This indicates that while differences exist, large fractions of them are still 
well matched to each other even out to the horizon. Thus the rounding errors in 
gridding do not affect the statistics of the images or the synthesized beams.

\subsection{Application to LWA data}\label{sec:LWA-data}

Here we demonstrate our software using narrow band data from the LWA station 
in New Mexico. This data is in LWA narrow-band transient buffer (TBN) format 
from 255 antennas within roughly a diameter of 100~m. The data is centreed at a 
frequency of 74.03~MHz, with a sample rate (equal to the bandwidth) of 100~kHz 
with 512 complex time samples per antenna in a A/D writeout time-scale of 
5.12~ms, a frequency resolution of 195.3125~Hz and dual polarization. There are 
391 such writeouts (or time stamps; each contains 512 time samples at 100~kHz 
sampling) yielding a total duration of 2~s. 

We corrected the cable delays, but otherwise assume the data is sufficiently 
calibrated to image directly. A test of EPICal on this data will be conducted 
in the future.

Fig.~\ref{fig:LWA-image} shows the image produced with MOFF imaging 
packaged in EPIC after averaging over $\approx$~20~ms (four writeouts) of data 
and the inner $\approx 80$ per cent of bandwidth (roughly 80~kHz). The image is 
shown in direction cosine coordinates -- $l$ along the horizontal axis and $m$ 
along the vertical axis. The flux scale is arbitrary. Even in this 
proof-of-concept demonstration, we see Cyg~A and Cas~A prominently as annotated, 
thus validating the functionality of EPIC.

\begin{figure}
  \includegraphics[width=\columnwidth]{figure9}
  % \includegraphics[width=\columnwidth]{LWA_MOFF_bandavg_image_4_iterations_analytic_aperture}
  % \includegraphics[width=\columnwidth]{LWA_MOFF_bandavg_image_4_iterations_analytic_aperture.eps}
  \caption{Image from LWA TBN data obtained with MOFF imaging using EPIC 
    package after averaging over 20~ms and $\approx 80$~kHz. The x- and y-axes
    denote direction cosines $l$ and $m$ respectively. The antenna voltages
    are compensated for their respective delays. The flux scale is arbitrary.
    Locations of Cyg~A and Cas~A are annotated.}
  \label{fig:LWA-image}
\end{figure}

\section{Imaging with Heterogeneous Antenna Array}\label{sec:versatility}

\begin{figure*}
\subfloat[][Simulated Image]{\label{fig:nonphysical-image}\includegraphics[width=0.5\linewidth]{figure10a.eps}}
\subfloat[][Normalized Radial Flux Density Profile]{\label{fig:norm-flux-density}\includegraphics[width=0.42\linewidth]{figure10b.eps}}
\caption{.}
\label{fig:versatility}
\end{figure*}

\section{Analysis and Feasibility}\label{sec:analysis}

We now investigate the feasibility of implementing the EPIC imager on current
and future radio telescopes. 

\subsection{Processing Volumes}

We have profiled the core routines of EPIC line-by-line for various ranges of 
parameters such as antenna filling fraction, maximum baseline length, bandwidth 
and frequency resolution, integration time-scale, etc. for HERA antenna layouts 
which are highly compact. However, we note that in general, the hardware and 
optimization of routines in place will determine the relative speeds of the 
different stages in the pipeline. 

Of all steps in the MOFF pipeline that are repeated for every writeout from 
the F-engine, the most expensive step even for dense HERA layouts is found to be 
the spatial two-dimensional FFT in the imaging stage relative to applying the 
sparse matrix gridding convolution, squaring or time-averaging. For instance, 
even in the conservative dense array layout scenario that makes these other 
stages even more expensive, the gridding convolution, squaring and time-averaging 
take up only $\lesssim 20$, $\lesssim 20$ and $\lesssim 5$ per cent respectively 
of the total processing time while the spatial Fourier transform takes up 
$\gtrsim 55$ per cent of the total time. With sparser arrays the gridding process 
will be be even faster. 

In visibility-based imaging, the predominant computational cost is at the 
X-engine requiring $\Nant(\Nant-1)/2$ complex multiplications per channel at 
every A/D writeout time-scale. 

In the following discussions, we will assume that the computational cost for
the MOFF imaging is determined by the spatial Fourier transform while  
that for visibility-based imaging comes from the cross-correlations. However, 
if non-linearities such as non-coplanarity of baselines \citep{cor08} and 
wide-field phenomena like the {\it pitchfork} effect \citep{thy15a,thy15b} 
are to be corrected for, the antenna-based illumination footprint can start 
becoming less compact in the measurement plane and can result in a costlier 
gridding process.

The number of complex multiplications and additions in the spatial Fourier 
transform implemented via FFT is $\approx \beta\,(4\Ngrid)\log_2(4\Ngrid)$ 
where $\Ngrid$ is the number of pixels on the grid, the factor 4 accounts for 
increase in number of pixels as a result of zero-padding before spatial Fourier 
transform, and $\beta$ is a constant that depends on the implementation of 
twiddle FFT algorithms \citep{bri74}. In our study, we set $\beta=5$, a 
value\footnote{http://www.fftw.org/speed/method.html} much more conservative 
than was indicated in \citet{mor11}. We set the number of complex 
multiplications in the X-engine in visibility-based imaging to 
$\Nant(\Nant-1)/2$.

We consider a variety of current and planned radio telescopes. Their antenna 
layouts are summarized in Table~\ref{tab:antenna-layouts}. The size of the 
layout gives the maximum baseline $b_\textrm{max}$. The grid spacing is 
determined by the science goals of the experiment in general. For our 
purpose, we assume a typical requirement that only the field of view of the 
antenna is to be imaged. This sets the grid spacing to be equal to the size 
of the antenna, $A_\textrm{a}$. Hence, 
$\Ngrid\simeq b_\textrm{max}^2/A_\textrm{a}$. 

\begin{table}
  \scriptsize
  \centering
  \caption{Radio telescopes and array layouts.}
  \label{tab:antenna-layouts}
  \begin{threeparttable}
  \begin{tabular}{ccccc} 
    \hline
    Telescope & Core & Number & Antenna & Frequency \\
              & size & of Antennas & size & \\
              & $b_\textrm{max}$ (in m) & $\Nant$ & $A_\textrm{a}$ (in m$^2$) & $f_0$ (in MHz) \\
    \hline
    MWA-112\tnote{a} & 1400 & 112 & 16 & 150 \\
    MWA-240\tnote{a} & 1400 & 240 & 16 & 150 \\
    MWA-496\tnote{a} & 1400 & 496 & 16 & 150 \\
    MWA-112\tnote{a} & 1400 & 1008 & 16 & 150 \\
    LOFAR-LC\tnote{b} & 3500 & 24 & 5809 & 50 \\
    LOFAR-HC\tnote{b} & 3500 & 48 & 745 & 150 \\
    LWA1 & 100 & 256 & 10 & 50 \\
    LWA-OV\tnote{c} & 200 & 256 & 10 & 50 \\
    HERA-19 & 70 & 19 & 154 & 150 \\
    HERA-37 & 98 & 37 & 154 & 150 \\
    HERA-331 & 294 & 331 & 154 & 150 \\
    HERA-6769\tnote{d} & 1330 & 6769 & 154 & 150 \\
    SKA1-LC\tnote{e} & 1000 & 750 & 962 & 150 \\
    SKA1-LCD\tnote{f} & 1000 & 192,000 & 2 & 150 \\
    CHIME & 100 & 1280 & 8 & 600 \\
    HIRAX\tnote{g} & 200 & 1024 & 28 & 600 \\
    \hline
  \end{tabular}
  \begin{tablenotes}
    \item[a] MWA-N denotes N tiles in the specified core diameter
    \item[b] LC and HC denotes low band and high band stations inside the 
      specified core diameter 
    \item[c] Owens Valley LWA
    \item[d] Hypothetically chosen to have a total collecting area of 
      1~km$^2$
    \item[e] This is the number of beamformed stations expected to be in the 
      core, roughly three-fourths of the total number
    \item[f] All dipoles inside the core are used as independent elements 
      without station beamforming
    \item[g] Hydrogen Intensity mapping and Real-time Analysis eXperiment
  \end{tablenotes}
  \end{threeparttable}
\end{table}

Fig.~\ref{fig:parameter-space-computations-instruments} shows the number of 
complex operations per frequency channel per cross-polarization per integration 
time-scale. Telescopes that fall to the left of the solid line indicate MOFF 
imaging is computationally more efficient than visibility-based imaging. All HERA 
layouts except HERA-19 and HERA-37 are in a region of parameter space 
where MOFF imaging holds the advantage. The dashed line showing future trajectory 
of HERA like systems will be clearly favoured by MOFF imaging. The dotted line is 
similarly a hypothetical trajectory for the MWA with more tiles added inside the 
same core diameter. The gray shaded area is for a projected LWA expansion and is 
also predominantly in the region favouring MOFF imaging. It is bounded by the LWA1 
and LWA-OV on the left and right respectively. The current (see 
Table~\ref{tab:antenna-layouts}) and a hypothetical expanded layout with a 
four-fold increase in number of elements over a 50 per cent increase in 
$b_\textrm{max}$ provide the bounds at the bottom and top respectively. Current 
instruments such as MWA and LOFAR lie in parameter space favouring 
visibility-based imaging. 

\begin{figure}
  \includegraphics[width=\columnwidth]{figure11}
  % \includegraphics[width=\columnwidth]{MOFF_FX_computations_fov_gridding_annotated}
  % \includegraphics[width=\columnwidth]{MOFF_FX_computations_fov_gridding_annotated.eps}
  \caption{Current and planned instruments in parameter space of
    number of complex multiplies and adds with MOFF and FX. The solid line
    is the boundary at which the number of operations with MOFF and 
    visibility-based imaging are equal. MOFF imaging is more efficient for 
    telescopes occupying the left of this line and vice versa. CHIME, HIRAX, 
    SKA1-LC, SKA1-LCD and all the HERA layouts except HERA-19 and HERA-37 lie 
    in the parameter space favoured by MOFF imaging. The dashed line shows the 
    projected trajectory of hypothetical expanded HERA layouts. The dotted line 
    similarly shows hypothetical expanded MWA layouts with more tiles added in 
    the same core. The gray shaded area denotes the projected trajectory of the 
    LWA bounded by LWA1 (left edge), LWA-OV (right edge), current layout 
    (bottom) and a four-fold increase in the number of elements within a 50 per 
    cent increase in the core size (top). Current instruments such as MWA and 
    LOFAR fall in a region favoured by visibility-based imaging.}
  \label{fig:parameter-space-computations-instruments}
\end{figure}

We now consider antenna array layouts described by three essential quantities 
in radio interferometry, namely, maximum baseline length, number of antennas,
and the size of each antenna. 

Fig.~\ref{fig:parameter-space-bll-nant-instruments} shows the boundaries where 
the ratio of the number of computations required with visibility-based imaging 
relative to MOFF imaging is unity. The different colored lines correspond to 
different antenna sizes (cyan - 1~m$^2$, blue - 7~m$^2$, purple - 16~m$^2$, 
green - 28~m$^2$, orange - 150~m$^2$, red - 740~m$^2$, gray - 5900~m$^2$). Solid 
line style in each color denotes the maximum number of antennas with the 
corresponding antenna size that can be densely packed inside various baseline 
lengths. The region to the right of the solid lines for corresponding antenna 
size represents a scenario of overlapping antennas that is physically 
impossible. Dashed lines of each color denote the boundary to the left of which 
visibility-based imaging is favoured for the corresponding antenna size. Region 
inside the wedge enclosed by the solid and dashed lines favours using the MOFF 
algorithm for the corresponding antenna size over visibility-based imaging. 

As antenna size increases the maximum number of antennas for a dense packing as 
a function of baseline length decreases. Hence, the solid lines shift leftward 
as antenna size increases. Similarly, with increase in antenna size, $\Ngrid$ 
also decreases when field of view imaging is achieved with an increasing grid 
spacing equal to antenna size and hence lowers the amount of computations 
required with the MOFF algorithm. This shifts the dashed curves leftward. 

The different antennas are color coded by roughly the class of antenna size 
they fall into. Thus symbols of one color falling into a wedge of the same color 
indicates MOFF imaging is favoured for those telescopes and vice versa. For 
e.g., MOFF imaging is favoured in HERA-331 and HERA-6769 because they are inside 
the wedge but not so in cases of HERA-19 and HERA-37. A majority of the 
next-generation radio telescopes, namely, HERA-331 and its future expanded 
versions, SKA1-LC, SKA1-LCD, HIRAX, and CHIME will fall in the regime where MOFF 
imaging will be desirable. LWA1 and LWA-OV are already very close to the dividing 
line. Their hypothetical expansions,\footnote{LWA1-x2x1 and LWA1-x4x1.5, and 
LWA-OVx2x1 and LWA-OVx4x1.5 denote two-fold and four-fold increase in number 
of antennas within a core diameter that is 1 and 1.5 times the current size of 
100~m and 200~m respectively for LWA1 and LWA-OV.} will be in the computational 
regime favoured by MOFF. For a fixed baseline length, regions favouring the MOFF 
algorithm tend to be towards large $\Nant$ indicating large-N dense array 
layouts with smaller antenna elements are best suited for deploying EPIC.

\begin{figure}
  \includegraphics[width=\columnwidth]{figure12}
  % \includegraphics[width=\columnwidth]{MOFF_FX_crossover_baseline_n-antennas_rho_fov_gridding_legended}
  % \includegraphics[width=\columnwidth]{MOFF_FX_crossover_baseline_n-antennas_rho_fov_gridding_legended.eps}
  \caption{Current and planned instruments in parameter space of
    baseline length and number of antennas with MOFF and FX. Line styles of 
    different colors denote different classes of antenna sizes (cyan - 1~m$^2$, 
    blue - 7~m$^2$, purple - 16~m$^2$, green - 28~m$^2$, orange - 150~m$^2$, 
    red - 740~m$^2$, gray - 5900~m$^2$). Solid line style in each color denotes 
    the maximum number of antennas with the corresponding antenna size that can 
    be packed inside various baseline lengths. The region to the right of the 
    solid lines for corresponding antenna size is physically disallowed. Dashed
    lines of each color denote the boundary to the left of which 
    visibility-based imaging is favoured for the corresponding antenna size. 
    Region inside the wedge enclosed by the solid and dashed lines favours using 
    the MOFF algorithm for the corresponding antenna size. These wedges shift 
    leftward with increasing antenna size. The different antennas are color 
    coded by roughly the class of antenna size they fall into. Thus symbols of 
    one color falling into a wedge of the same color indicates MOFF imaging is 
    advantageous for those telescopes and vice versa. For example, MOFF imaging
    is favoured in HERA-331 and HERA-6769 because they are inside the wedge 
    but not so in cases of HERA-19 and HERA-37.}
  \label{fig:parameter-space-bll-nant-instruments}
\end{figure}

\subsection{Data Throughput}

We elaborate on the I/O data rates required with the MOFF and visibility-based
algorithms. This is particularly relevant in the context of radio transient 
detection. 

Implementation of the MOFF algorithm with EPIC yields calibrated images on
time-scales of the output generated by the digitizer and is set by the inverse
of the frequency channel width. These calibrated images are accumulated and 
averaged to a certain time-scale depending on science or hardware requirements,
or when the sky has rotated significantly, whichever is lesser. In 
visibility-based algorithms, the visibilities are accumulated and averaged to 
this time-scale before images are produced. Thus the data throughput (in samples 
per second) per cross-polarization with MOFF and X-engine outputs are: 
\begin{align}
  r_\textrm{MOFF} &\sim \frac{4\Ngrid}{\Delta t} \left(\frac{\Delta B}{\Delta f}\right) \\
  r_\textrm{X} &\sim 2\,\frac{\Nant(\Nant-1)/2}{\Delta t} \left(\frac{\Delta B}{\Delta f}\right),
\end{align}
where, the factor 4 in the expression for $r_\textrm{MOFF}$ accounts for imaging
after zero-padding the gridded electric fields, the leading factor of 2 in the
expression for $r_\textrm{X}$ accounts for the real and imaginary parts of the
complex visibilities, $\Delta B$ is the bandwidth, $\Delta f$ is the frequency 
resolution, and $\Delta t$ is the time-scale over which the transient phenomenon
is sampled and the data (images or visibilities) are averaged to.

Though a full understanding of the FRB phenomena is yet to emerge, there are 
indications the time-scales of FRB objects are $\Delta t \sim 1$--10~ms 
\citep{tho13}. For a telescope like HERA, $\Delta B \simeq 100$~MHz, 
$\Delta f \simeq 100$~kHz. For HERA-331, $\Nant=331$ and with a grid 
spacing to image the field of view, $\Ngrid \simeq 441$ or 
$\Ngrid \simeq 1024$ if $\Ngrid$ is preferred as a power of 2 in either 
direction. Using 8 bytes for each floating point sample in the MOFF images and 
4 bytes each for real and imaginary parts of visibility samples, the throughputs 
are $r_\textrm{MOFF} \lesssim 3$~GB~s$^{-1}$ and 
$r_\textrm{X} \simeq 41$~GB~s$^{-1}$. For HERA-37, 
$r_\textrm{MOFF} \lesssim 190$~MB~s$^{-1}$ and 
$r_\textrm{X} \simeq 0.5$~GB~s$^{-1}$. In such a case, The X-engine throughput 
corresponds to an extreme rate of $\simeq 1.8$~TB an hour per 
cross-polarization. Conversely, for the same data throughput, the MOFF algorithm 
can sample even shorter time-scales. 

Table~\ref{tab:data-rates} shows these data rates for some of the current and 
planned telescopes for $\Delta t=10$~ms. In almost all cases listed, even with 
conservative estimates, the MOFF algorithm provides very economic data 
throughput for a majority of next generation radio telescopes with a dense 
layout. The most significant advantage is that calibrated images are also 
available at no extra cost.

\begin{table}
  \centering
  \caption{Data throughput per cross-polarization for various telescopes with 
    MOFF and X-engine outputs on time-scales of $\Delta t=10$~ms assuming 
    $\Delta B=100$~MHz and $\Delta f=100$~kHz.}
  \label{tab:data-rates}
  \begin{threeparttable}
  \begin{tabular}{ccc} 
    \hline
    Telescope\tnote{a} & $r_\textrm{MOFF}$\tnote{b} & $r_\textrm{X}$ \\
              & (GB~s$^{-1}$)\tnote{c} & (GB~s$^{-1}$)\tnote{c} \\
    \hline
    LWA1 & $\simeq 3$ & $\simeq 24.3$ \\
    LWA-OV & $\simeq 12$ & $\simeq 24.3$ \\
    HERA-19 & $\lesssim 0.19$ & $\simeq 0.13$ \\
    HERA-37 & $\lesssim 0.19$ & $\simeq 0.5$ \\
    HERA-331 & $\lesssim 3$ & $\simeq 41$ \\
    CHIME & $\lesssim 6.1$ & $\simeq 610$ \\
    \hline
  \end{tabular}
  \begin{tablenotes}
    \item[a] Antenna layouts are listed in Table~\ref{tab:antenna-layouts}.
    \item[b] $\Ngrid$ is usually greater than true value because of 
      rounding to the next power of 2 in either direction. Thus 
      $r_\textrm{MOFF}$ is usually lesser than the conservative values 
      listed here.
    \item[c] We assume 8 bytes for each real sample from MOFF images, and
      4 bytes each for real and imaginary parts of visibility samples.
  \end{tablenotes}
  \end{threeparttable}
\end{table}

\section{Conclusions}\label{sec:conclusions}

As radio astronomy is entering a new era, advances in instrumentation have to
be accompanied by equal advances in processing techniques to manage 
computational resources. Many future radio telescopes such as the SKA, HERA and 
LWA are headed towards the large-N dense array layout model for which 
computational cost from traditional FX/XF correlator-based architecture and 
visibility-based imaging starts rising steeply. We have provided the first 
software demonstration of a general purpose imaging algorithm using our generic 
and efficient EPIC software that is designed to bring this cost down from 
$\mathcal{O}(\Nant^2)$ to $\mathcal{O}(\Ngrid\log_2 \Ngrid)$. Under the class of 
direct imaging 
techniques, ours is one of the most generic -- neither does it place any 
constraint on the array layout to be on a regular grid nor does it require the
antenna array to be homogeneous. 

Our EPIC package, now publicly available, written in object oriented Python, is 
highly modularized and parallelizable. It includes an implementation of the 
MOFF algorithm in addition to visibility-based software holography imaging and 
a data simulator for sky models. It is designed to provide a development 
platform to compare different imaging approaches and serve as a stepping stone 
for real-life GPU/FPGA-based implementation on telescopes. It has been 
successfully tested on simulated MWA observations as well as real LWA 
observations. 

The MOFF algorithm packaged with EPIC is already found to be most suitable 
for many present and planned radio telescopes such as the LWA, HERA, CHIME,
HIRAX and SKA. In general, MOFF is most suited to operate in the region of 
parameter space characterized by dense packing of a large number of antennas 
especially when consisting of a large number of small antenna elements. 

It is seen to have significant savings in data throughput relative to a 
X-engine based pipeline. A unique advantage is the instantaneous availability 
of calibrated time-domain images at no extra cost. Hence, it is a compelling 
candidate for time-domain radio astronomy, e.g. search for and monitoring of 
transients. Potentially, it could allow on-chip processing thus lowering even 
further the already relatively low I/O bandwidth shown in 
Table~\ref{tab:data-rates} except when a transient event is detected. Transient 
detection pipelines at the backend of EPIC can be fine-tuned to target fast 
transients such as the Fast Radio Bursts \citep[FRB;][]{tho13} on millisecond 
time-scales at GHz frequencies or slow transients from planetary and exoplanetary 
origins at frequencies around 100~MHz. 

Thus, EPIC with the MOFF algorithm packaged is uniquely poised to offer a
substantial advantage to imaging with large-N dense arrays typical of 
next-generation radio telescopes as well as push the frontiers of 
time-domain astronomy to fill gaps in understanding the science behind 
phenomena responsible for extreme transient events in the Universe.

In the near future, we plan to upgrade our current Python implementation 
of EPIC to a GPU-based pipeline in order to operate on real-time data and 
develop a transient trigger and monitor backend. In the meanwhile, we plan 
to demonstrate the capability of EPIC to calibrate and image from heterogeneous 
arrays and incorporate corrections for non-coplanarity of baselines and 
direction-dependence of calibration. 

\section*{Acknowledgements}

We thank Larry D'Addario, Gregg Hallinan, Joseph Lazio and Harish Vedantham for 
their valuable inputs, and Greg Taylor for providing us with LWA data. This work 
has been supported by the National Science Foundation through award AST-1206552. 
Construction of the LWA has been supported by the Office of Naval Research under 
Contract N00014-07-C-0147. Support for operations and continuing development of 
the LWA1 is provided by the National Science Foundation under grant AST-1139974 
of the University Radio Observatory program.

%%%%%%%%%%%%%%%%%%%% REFERENCES %%%%%%%%%%%%%%%%%%

\bibliographystyle{mnras}
\bibliography{epic} 
% \bibliography{../epic} 
% \input{ms.bbl}

%%%%%%%%%%%%%%%%% APPENDICES %%%%%%%%%%%%%%%%%%%%%

\appendix

\section{Software Architecture}\label{sec:software-modules}

EPIC is built using object oriented programming in Python and is built on
carefully crafted modules which closely represent real-life entities in radio 
interferometer arrays and observations. The essential modules along with their
key attributes and methods are illustrated in Fig.~\ref{fig:software-modules}.
These modules are described below.

\begin{figure*}
  \includegraphics[width=\linewidth]{figureA1}
  % \includegraphics[width=\linewidth]{EPIC-modules}
  % \includegraphics[width=\linewidth]{EPIC-modules.eps}
  \caption{Software architecture of EPIC with core modules, their essential
    attributes and functions. The antenna module forms the fundamental building 
    block. It consists of electric field time-series and spectra and the 
    F-engine that performs a temporal FFT to obtain electric field spectra from 
    the time-series. The interferometer module is made of a pair of antenna 
    modules. Its main function is the X-engine (FX or XF) to produce visibility 
    spectra. The antenna array module is made of all individual antenna modules
    as its components and contains collective properties about the antenna 
    subsystems. Its core function is the creation of antenna-to-grid mapping, 
    gridded aperture weights and electric fields. The interferometer array 
    module is very similar in principle to the antenna array module except it 
    operates on cross-correlations and produces gridded visibilities. The image 
    module takes gridded electric fields or visibilities and performs a 
    two-dimensional spatial FFT (and squares the intermediate image in case 
    of the former) to produce output images. Broadly, the MOFF algorithm is 
    implemented by modules below the horizontal dashed line while the 
    visibility-based imaging uses modules above the line. The exact processing 
    pathway implementing the MOFF algorithm is shown in bolded modules.}
  \label{fig:software-modules}
\end{figure*}

\subsection{Antenna Module}

The antenna module is a fundamental building block upon which all the other 
modules are built. There is one antenna module per antenna each having 
attributes -- the propagated electric field time-series, $E(t)$, and spectrum 
$\widetilde{E}(f)$ for both polarizations. The most important function inside 
this module is the F-engine that Fourier transforms time-series electric field 
data into spectra. 

The other function (not shown in the figure) is to update the data as new data 
streams in. This can also be parallelized. Another important attribute consists 
of antenna flags (not shown in the figure) for each polarization appropriate 
for the data stream being held by the module. 

\subsection{Interferometer Module}

The interferometer module holds the attributes and functions pertaining to
a pair of antennas and represents the cross-correlation information obtained
from the pair. Its primary attributes are the two antenna modules. It also
contains four cross-polarized visibility time-series (even for the FX 
correlator for diagnostic purposes) and spectra. 

The critical component of the interferometer module is the X-engine. This is 
essentially a software analog of hardware correlators of real telescope 
systems. The X-engine can be toggled between two states of operation, 
namely, the FX and XF modes. The FX mode obtains the electric field spectra, 
$\widetilde{E}(f)$ from the individual antenna modules inside this module and 
multiplies the two to obtain visibility spectra, $\widetilde{V}(f)$. On the 
other hand, the XF mode cross-correlates the electric field time-series from 
its Antenna modules to obtain the visibilities as a function of lags, 
$\widetilde{V}_t(t)$, which is then Fourier transformed to obtain 
$\widetilde{V}(f)$. Both modules can operate on dual-polarizations to obtain 
all four cross-polarizations.

The other attributes (not shown in the figure) are the flags applicable for each
cross-polarization for the current data stream. Similar to the antenna module,
it has an update function that can update the visibilities $\widetilde{V}_t(t)$ 
or $\widetilde{V}(f)$ directly rather than through the electric fields of its 
component antennas. This functionality is to allow EPIC to operate while 
attached to the backend of traditional correlator systems. This feature is not 
utilized for purposes of this paper.

This module forms the fundamental unit for the interferometer array module 
(to be discussed below) and in general for visibility-based correlator and 
imaging systems. 

\subsection{Antenna Array Module}

The antenna array module consists of all the antenna modules as its attributes
and represents the collective properties of its component antennas. By virtue of 
holding each antenna data independently in their respective modules, the F-engine 
for the entire array can be distributed to the F-engines of the component 
antenna modules thus achieving a highly parallelized F-engine while emulating 
real telescope systems.

The primary attributes held by this module are the antenna aperture 
illumination weights and electric fields projected on the grid using the 
gridding convolution method described above and implemented by the gridding 
function in this module. Significant parts of the antenna-to-grid mapping and 
gridding convolution are parallelizable across antennas and frequencies.

Individual antenna flags are carried over as additional weights to be applied
to the gridded aperture illumination and electric fields. A series of data 
streams can be stacked up to take advantage of the array optimization available 
in Python. This module is also equipped to manage dual-polarization. 

\subsection{Interferometer Array Module}

Similar to the antenna array module, the interferometer array module consists of
individual interferometer modules. It can parallelize the correlator operations
by distributing the X-operation over the X-engines of its component 
interferometer modules. The interferometer-to-grid mapping and gridding 
convolution are very similar in nature to that of the antenna array module. 
Flag-based grid weights, stacking and ability to handle all four 
cross-polarizations are built into this module. 

\subsection{Image Module}

The image module is built as a general purpose module that can switch between 
operating on gridded electric fields or visibilities. At its heart, it consists
of a two-dimensional spatial FFT where the padding can be specified by the user 
to control the resolution in the output images. In case of MOFF imaging, there 
is an additional step of squaring the holographic electric field images. 

Besides its core functions of spatial Fourier transform and squaring, it can 
stack, accumulate and average images, and optionally remove the antenna
auto-correlations centreed around the zero-spacing pixel in the $uv$ plane. 
It also handles all four cross-polarization products. Currently, it supports 
writing data out in standard FITS format. 

% \section{Some extra material}

% If you want to present additional material which would interrupt the flow of the main paper,
% it can be placed in an Appendix which appears after the list of references.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Don't change these lines
\bsp	% typesetting comment
\label{lastpage}
\end{document}

% End of mnras_template.tex
